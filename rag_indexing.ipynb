{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eebd524",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "-- Multi Representation indexing:\n",
    "First we generate a summary for a document using an LLM, and we store the document in a particular document DB. Then during retrieval we use the summary to retrieve the full document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -q install langchain_community tiktoken langchain-deepseek langchainhub chromadb langchain_chroma langchain dotenv bs4 langchain-text-splitters langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde07230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "# Loading my LLM API Key\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"qwen3-embedding:0.6b\"\n",
    "DEEPSEEK_MODEL_NAME='deepseek-chat'\n",
    "\n",
    "OLLAMA_EMBEDDING = OllamaEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "DEEPSEEK_LLM = ChatDeepSeek(model=DEEPSEEK_MODEL_NAME, temperature=0, api_key=os.getenv('DEEPSEEK_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader('https://lilianweng.github.io/posts/2023-06-23-agent/')\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader('https://lilianweng.github.io/posts/2024-02-05-human-data-quality/')\n",
    "docs.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7ffb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chain = (\n",
    "    {'doc': lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | DEEPSEEK_LLM\n",
    "    |StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {'max_concurrency': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_classic.storage import InMemoryByteStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"summaries\", embedding_function= OLLAMA_EMBEDDING)\n",
    "\n",
    "store = InMemoryByteStore()\n",
    "id_key = 'doc_id'\n",
    "\n",
    "# The retriever\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key\n",
    ")\n",
    "\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Docs linked to summaries\n",
    "summary_docs = [\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]}) for i, s in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add \n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"High quality annotated data\"\n",
    "sub_docs = vectorstore.similarity_search(query, k=1)\n",
    "sub_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(query) # In the new version we no longer use get_relevant_document, rather we use invoke.\n",
    "retrieved_docs[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
